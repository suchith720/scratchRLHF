{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f0d8a-3050-49e8-aa12-3b8320e0f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp reward_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3609f49-6a0d-4add-8e1b-ce0515d6bda9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "/scratch/scai/phd/aiz218323/projects/scratchRLHF/scratchRLHF/03_reward_model.py does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshowdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m; \u001b[43mnbdev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbdev_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/fastcore/script.py:112\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m     mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back)\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mod: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: sys\u001b[38;5;241m.\u001b[39margv\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/nbdev/doclinks.py:142\u001b[0m, in \u001b[0;36mnbdev_export\u001b[0;34m(path, procs, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   procs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(nbdev\u001b[38;5;241m.\u001b[39mexport, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m L(procs)]\n\u001b[1;32m    141\u001b[0m files \u001b[38;5;241m=\u001b[39m nbglob(path\u001b[38;5;241m=\u001b[39mpath, as_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39msorted(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files: \u001b[43mnb_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m add_init(get_config()\u001b[38;5;241m.\u001b[39mlib_path)\n\u001b[1;32m    144\u001b[0m _build_modidx()\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/nbdev/export.py:77\u001b[0m, in \u001b[0;36mnb_export\u001b[0;34m(nbname, lib_path, procs, debug, mod_maker, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m     warn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotebook \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnbname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m uses `#|export` without `#|default_exp` cell.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://nbdev.fast.ai/getting_started.html for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m mm \u001b[38;5;241m=\u001b[39m \u001b[43mmod_maker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlib_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m mm\u001b[38;5;241m.\u001b[39mmake(cells, all_cells, lib_path\u001b[38;5;241m=\u001b[39mlib_path)\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/nbdev/maker.py:69\u001b[0m, in \u001b[0;36mModuleMaker.__init__\u001b[0;34m(self, dest, name, nb_path, is_new, parse)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname \u001b[38;5;241m=\u001b[39m dest\u001b[38;5;241m/\u001b[39m(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_new: dest\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdest2nb \u001b[38;5;241m=\u001b[39m nb_path\u001b[38;5;241m.\u001b[39mrelpath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname\u001b[38;5;241m.\u001b[39mparent)\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# %% \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdest2nb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: /scratch/scai/phd/aiz218323/projects/scratchRLHF/scratchRLHF/03_reward_model.py does not exist"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a46a6a-98c9-4e71-8090-c5602911c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd, re, numpy as np, joblib, os\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1e1a3-861b-4c89-b90d-abf43fffad32",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a224f-8d5e-42ff-814a-6b4db8b2956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_title(content):\n",
    "    title_matches = re.findall(r'\\\\title\\{(.*?)\\}', content, re.DOTALL)\n",
    "    title = title_matches[0].strip() if title_matches else pd.NA\n",
    "    return title\n",
    "\n",
    "def extract_abstract(content):\n",
    "    abstract_matches = re.findall(r'\\\\begin\\{abstract\\}(.*?)\\\\end\\{abstract\\}', content, re.DOTALL)\n",
    "    abstract = abstract_matches[0].strip() if abstract_matches else pd.NA\n",
    "    return abstract\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07607a-efaf-41af-bbee-a14442fd90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_train_test_split(X, y, pct=0.8):\n",
    "    n_data = len(y)\n",
    "    n_trn = int(n_data * pct)\n",
    "\n",
    "    rnd_idx = np.random.permutation(n_data)\n",
    "    trn_idx, tst_idx = rnd_idx[:n_trn], rnd_idx[n_trn:]\n",
    "    X_trn, y_trn = type(X)({k:v[trn_idx] for k,v in X.items()}), y[trn_idx]\n",
    "    X_tst, y_tst = type(X)({k:v[tst_idx] for k,v in X.items()}), y[tst_idx]\n",
    "\n",
    "    return X_trn, y_trn, X_tst, y_tst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b260e-93d8-448d-b73b-cf37cdc37a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(pkl_file, x_file, y_file):\n",
    "    if os.path.exists(pkl_file):\n",
    "        X, y = joblib.load(pkl_file)\n",
    "    else:\n",
    "        X_df = pd.read_csv(x_file, header=None, names=['content'])\n",
    "        X_df['title'] = X_df['content'].apply(extract_title)\n",
    "        X_df['abstract'] = X_df['content'].apply(extract_abstract)\n",
    "    \n",
    "        tokz = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "        text = [f'{title} :: {abstract}' for title,abstract in zip(X_df['title'], X_df['abstract'])]\n",
    "        X = tokz(text, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "    \n",
    "        y = pd.read_csv(y_file, header=None)\n",
    "        y = pd.Categorical(y[0], ordered=True, categories=['Reject', 'Accept']).codes\n",
    "        joblib.dump((X, y), pkl_file)\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55306f-91e1-4244-9c68-342dcb22b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RewardDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        o = {k:v[idx] for k,v in self.X.items()}\n",
    "        o['labels'] = self.y[idx]\n",
    "        return o\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e03e51-5347-4eb0-b6ee-04ff2c25744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24801de4-261f-4a26-8fea-e74fffca975d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec7101-43fc-4587-bd8a-a7a339be501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/deepreviewer/'\n",
    "output_dir = '/home/scai/phd/aiz218323/scratch/outputs/scratchRLHF/reward_model/'\n",
    "pkl_file = '/home/scai/phd/aiz218323/scratch/datasets/processed/scratchRLHF/reward_model.joblib'\n",
    "\n",
    "x_file = f'{data_dir}/train_papers.csv'\n",
    "y_file = f'{data_dir}/train_decision.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885156c1-9c4a-4583-a0b2-1af5277e366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(x_file, y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027aeb3-7281-4694-8325-debc9aa16921",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, y_trn, X_tst, y_tst = get_train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17179bc-6beb-465c-b1d3-1a8edd28910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = RewardDataset(X_trn, y_trn)\n",
    "tst_dataset = RewardDataset(X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfd0e6-da0e-45c7-89a8-6948b3fa0d8f",
   "metadata": {},
   "source": [
    "## `Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d80f9-0bbf-45df-b88a-38be72fdc268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "comet_ml version 3.39.1 is installed, but version 3.43.2 or higher is required. Please update comet_ml to the latest version to enable Comet logging with pip install 'comet-ml>=3.43.2'.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9362dd-4f55-452f-9a32-cc1d3af9eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9021cf-4636-4583-ba44-49ac3ca4fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trn_dataset,\n",
    "    eval_dataset=tst_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf166c9-b276-4f9a-9ba9-108b88159ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbe1ce-9e16-451d-a6c2-965c465ba26b",
   "metadata": {},
   "source": [
    "## `__main__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c429f3a-4cd5-4f2a-991d-5c84f92d7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    data_dir = '/home/scai/phd/aiz218323/scratch/datasets/deepreviewer/'\n",
    "    output_dir = '/home/scai/phd/aiz218323/scratch/outputs/scratchRLHF/reward_model/'\n",
    "    pkl_file = '/home/scai/phd/aiz218323/scratch/datasets/processed/scratchRLHF/reward_model.joblib'\n",
    "    \n",
    "    x_file = f'{data_dir}/train_papers.csv'\n",
    "    y_file = f'{data_dir}/train_decision.csv'\n",
    "\n",
    "    X, y = load_data(x_file, y_file)\n",
    "    X_trn, y_trn, X_tst, y_tst = get_train_test_split(X, y)\n",
    "\n",
    "    trn_dataset = RewardDataset(X_trn, y_trn)\n",
    "    tst_dataset = RewardDataset(X_tst, y_tst)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        save_strategy=\"steps\",\n",
    "        eval_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=trn_dataset,\n",
    "        eval_dataset=tst_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    results = trainer.evaluate()\n",
    "    print(\"Evaluation results:\", results)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
